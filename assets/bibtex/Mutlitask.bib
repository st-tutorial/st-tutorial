@inproceedings{Weiss2017,
  author={Ron J. Weiss and Jan Chorowski and Navdeep Jaitly and Yonghui Wu and Zhifeng Chen},
  title={Sequence-to-Sequence Models Can Directly Translate Foreign Speech},
  year=2017,
  booktitle={Proc. Interspeech 2017},
  pages={2625--2629},
  doi={10.21437/Interspeech.2017-503},
  url={http://dx.doi.org/10.21437/Interspeech.2017-503}
}

@article{Berard2018EndtoEndAS,
  title={End-to-End Automatic Speech Translation of Audiobooks},
  author={Alexandre Berard and L. Besacier and A. Kocabiyikoglu and Olivier Pietquin},
  journal={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year={2018},
  pages={6224-6228}
}


@inproceedings{le-etal-2020-dual,
    title = "Dual-decoder Transformer for Joint Automatic Speech Recognition and Multilingual Speech Translation",
    author = "Le, Hang  and
      Pino, Juan  and
      Wang, Changhan  and
      Gu, Jiatao  and
      Schwab, Didier  and
      Besacier, Laurent",
    booktitle = "Proceedings of the 28th International Conference on Computational Linguistics",
    month = dec,
    year = "2020",
    address = "Barcelona, Spain (Online)",
    publisher = "International Committee on Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.coling-main.314",
    doi = "10.18653/v1/2020.coling-main.314",
    pages = "3520--3533",
    abstract = "We introduce dual-decoder Transformer, a new model architecture that jointly performs automatic speech recognition (ASR) and multilingual speech translation (ST). Our models are based on the original Transformer architecture (Vaswani et al., 2017) but consist of two decoders, each responsible for one task (ASR or ST). Our major contribution lies in how these decoders interact with each other: one decoder can attend to different information sources from the other via a dual-attention mechanism. We propose two variants of these architectures corresponding to two different levels of dependencies between the decoders, called the parallel and cross dual-decoder Transformers, respectively. Extensive experiments on the MuST-C dataset show that our models outperform the previously-reported highest translation performance in the multilingual settings, and outperform as well bilingual one-to-one results. Furthermore, our parallel models demonstrate no trade-off between ASR and ST compared to the vanilla multi-task architecture. Our code and pre-trained models are available at https://github.com/formiel/speech-translation.",
}

@article{Sperber2019,
 author = {Sperber, Matthias and Setiawan, Hendra and Gollan, Christian and Nallasamy, Udhyakumar and Paulik, Matthias},
 journal = {Transactions of the Association for Computational Linguistics (TACL)},
 keywords = {speech recognition,speech translation,consistency},
 title = {{Consistent Transcription and Translation of Speech}},
 url = {https://www.mitpressjournals.org/doi/pdf/10.1162/tacl_a_00340},
 year = {2020}
}


@article{Sperber2019,
 author = {Sperber, Matthias and Neubig, Graham and Niehues, Jan and Waibel, Alex},
 journal = {Transactions of the Association for Computational Linguistics (TACL)},
 keywords = {attentional encoder-decoder,multi-stage model,speech translation},
 title = {{Attention-Passing Models for Robust and Data-Efficient End-to-End Speech Translation}},
 url = {https://arxiv.org/abs/1904.07209},
 year = {2019}
}


@inproceedings{anastasopoulos+chiang:naacl2018,
    author = "Anastasopoulos, Antonios and Chiang, David",
    title = "Tied Multitask Learning for Neural Speech Translation",
    booktitle = "Proc. NAACL HLT",
    year = "2018",
    pages = "82--91",
    location = "New Orleans, Louisiana",
    volume = "1"
}

@article{3132409069354fa087182c81827e780d,
title = "Advances in joint CTC-attention based end-to-end speech recognition with a deep CNN encoder and RNN-LM",
author = "Takaaki Hori and Shinji Watanabe and Yu Zhang and William Chan",
note = "Publisher Copyright: Copyright {\textcopyright} 2017 ISCA. Copyright: Copyright 2017 Elsevier B.V., All rights reserved.; 18th Annual Conference of the International Speech Communication Association, INTERSPEECH 2017 ; Conference date: 20-08-2017 Through 24-08-2017",
year = "2017",
doi = "10.21437/Interspeech.2017-1296",
language = "English",
volume = "2017-August",
pages = "949--953",
journal = "Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH",
issn = "2308-457X",
}

@InProceedings { bahar2019:st-comparison,
author= { Bahar, Parnia and Bieschke, Tobias and Ney, Hermann },
title= {A comparative study on end-to-end speech to text translation},
booktitle= {IEEE Automatic Speech Recognition and Understanding Workshop},
year= 2019,
pages= {792-799},
address= {Sentosa, Singapore},
month= dec,
booktitlelink= {http://asru2019.org/wp/},
pdf = {https://www-i6.informatik.rwth-aachen.de/publications/downloader.php?id=1121&row=pdf}
}

